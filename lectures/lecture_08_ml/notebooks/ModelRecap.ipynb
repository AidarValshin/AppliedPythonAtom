{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML\n",
    "\n",
    "<b>Томас Митчел: “Компьютерная программа обучается на основе опыта E относительно некоторого класса задач T и меры качества P, если качество решения этих задач (относительно P) улучшается с приобретением опыта E”.</b>\n",
    "\n",
    "- Т - задача: Обучение с учителем, Обучение без учителя, Обучение с подкреплением, и тд.\n",
    "- P - метрика: Численное значение показывающее насколько хорошо алгоритм решает задачу.\n",
    "- E - опыт: Для алгоритмов это данные (с метками и без)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/ML.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Пайплайн машинного обучения</i>:\n",
    "- Задача\n",
    "- Метрика качества\n",
    "- Данные (признаковое описание объектов и целевые метки)\n",
    "- Правильная валидация (алгоритм должен быть обобщаемым)\n",
    "- Выбор модели (класса моделей)\n",
    "- Подготовка признаков (в соответствии с моделью)\n",
    "- Обучение (подбор параметров, оптимизируя метрику)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/Val.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Со временем так нельзя!!! Иначе заглянем в будущее</b>\n",
    "<img src=\"imgs/TimeVal.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У модели есть параметры, которые оптимизируются в процессе обучения. Гиперпараметры задаются извне. Мы их подбираем на кросс-валидации. Например: веса в регрессии - это параметры, коэффициент регуляризации - гиперпараметр, который мы задаем извне. В деревьях, порог сплита - параметр, глубина дерева - гиперпараметр\n",
    "\n",
    "<b>Почему нельзя сделать коэффициент регуляризации параметром?</b>\n",
    "\n",
    "<img src=\"imgs/Parameters.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/MLE.jpg\">\n",
    "<b>Maximum likelihood estimation</b>\n",
    "- Делаем предположение из какого распределения точки\n",
    "- Хотим максимизировать вероятность появления точек ВСЕХ одновременно -> подставим координаты в вероятность, перемножим\n",
    "- Максимизация произведения = максимизация логарифма произведения = максимизация суммы логарифмов\n",
    "- Максимизация $f(x)$ = минимизация $-f(x)$\n",
    "- На что можем влиять у $f(x)$ ? на параметры!\n",
    "- Получаем функцию, оптимизируемую относительно параметров - функцию потерь!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример для линейной регрессии:\n",
    "Для решения этой задачи нам нужно определиться с метрикой качества, которая покажет степень соответствия данной модели и тренировочных данных. Для этого воспользуемся методом максимизации правдоподобия.\n",
    "\n",
    "Правдоподобием называют вероятность того, что данная выборка была семплирована из данного распределения. Если объекты независимы и одинаково распределённы, то правдоподобие вычисляется как:\n",
    "$$\n",
    "    \\mathcal {L}_\\theta = \\prod_{i=1}^{N} P_\\theta(\\vec{x}_i)\n",
    "$$\n",
    "\n",
    "Т.к. большенство распределений параметрические, правдоподобие удобно использовать для того, чтобы оценить параметры распределения из которого появилась выборка. Для этого нужно найти такое $\\theta$ при котором правдоподобие будет максимальным. \n",
    "\n",
    "Посмотрим на нашу модель с вероятностной точки зрения.\n",
    "\n",
    "$$ \n",
    "y = \\mathbb{E}\\left[ p(t|x,w,\\sigma^{2}) \\right]\n",
    "$$\n",
    "\n",
    "Выпишем фунцию правдоподобия для нашего набора данных. Сразу возьмем логарифм правдоподобия, т.к. он поможет нам избавиться от произведения и степени экспоненты в нормальном распределении\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    " \\log \\left(\\mathcal {L}\\right) \n",
    "              &=& \\log \\prod_{i=1}^{N} \\mathcal{N}(\\vec{w}^T \\vec{x}_i,\\,\\sigma^{2}) \\\\\n",
    "              &=& \\sum_{i=1}^n \\log \\mathcal{N}\\left( \\vec{w}^T \\vec{x}_i, \\sigma^2 \\right) \\\\ \n",
    "              &=& \\sum_{i=1}^n \\log \\frac {1}{\\sigma {\\sqrt {2\\pi}}}\\;e^{-{\\frac {(y_i-\\vec{w}^T \\vec{x}_i )^{2}}{2\\sigma ^{2}}}} \\\\\n",
    "              &=& -n \\log \\sigma {\\sqrt {2\\pi}} -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n \n",
    "                  \\left(y_i - \\vec{w}^T \\vec{x}_i\\right)^2\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Таким образом задача сводится к максимизации правдоподобия.\n",
    "$$ \n",
    "\\begin{array}{rcl}\n",
    "\\hat{w} &=& \\arg \\max_{w} log\\left(\\mathcal {L}\\right) \\\\ \n",
    "        &=& \\arg \\max_{w} -n \\log \\sigma {\\sqrt {2\\pi}} -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n \\left(y_i - \\vec{w}^T \\vec{x}_i\\right)^2 \\\\ \n",
    "        &=& \\arg \\max_{w} - \\sum_{i=1}^n \\left(y_i - \\vec{w}^T \\vec{x}_i\\right)^2 \\\\ \n",
    "        &=& \\arg \\min_{w} L\\left(X, \\vec{y}, \\vec{w}\\right)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как подобрать оптимальные параметры?\n",
    "### -> методы оптимизации\n",
    "<img src=\"imgs/Optimization.png\">\n",
    "\n",
    "Один из простейших методов - градиентный спуск\n",
    "\n",
    "<img src=\"imgs/GD.png\">\n",
    "\n",
    "Находим направление наискорейшего убывания функции - антиградиент\n",
    "\n",
    "<img src=\"imgs/CostGradient.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача регрессии\n",
    "\n",
    "- $X$ - матрица-описание объектов, дизайн-матрица;\n",
    "- $Y$ - матрица-характеристики объектов;\n",
    "- $f$ - зависимость - некоторый метод подсчета характеристик объектов основываясь на их описании;\n",
    "- $\\left(X, Y = f\\left(X\\right)\\right)$ - наблюдения;\n",
    "- $S = \\left\\{X_i, Y_i\\right\\}_{i=1}^N$ - обучающая выборка - набор $N$ наблюдений - пары (описание объекта - значение);\n",
    "- $\\hat f$ - регрессионная модель - функция которая аппроксимирует исходную зависимость $f$.\n",
    "\n",
    "<img src=\"imgs/Regression.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
